{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Times New Roman\" size=5>\n",
        "<div dir=rtl align=\"center\">\n",
        "<font face=\"Times New Roman\" size=5>\n",
        "</font>\n",
        "<br>\n",
        "<img src=\"https://static.tildacdn.one/tild3639-3035-4131-a461-363737393037/noroot.png\" alt=\"University Logo\" width=\"400\" height=\"224\">\n",
        "<br>\n",
        "<font face=\"Times New Roman\" size=5 align=center>\n",
        "Sharif University of Technology\n",
        "<br>\n",
        "Electrical Engineering Department\n",
        "</font>\n",
        "<br>\n",
        "<font size=6>\n",
        "Assignment 5: Accuracy Measures\n",
        "</font>\n",
        "<br>\n",
        "<font size=4>\n",
        "Zahra Helalizadeh 400102193\n",
        "<br>\n",
        "</font>\n",
        "<font size=4>\n",
        "Spring 2025\n",
        "<br>\n",
        "</font>\n",
        "<font face=\"Times New Roman\" size=4>\n",
        "</font>\n",
        "</div></font>"
      ],
      "metadata": {
        "id": "XmF3_sG4axNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "In this notebook, we will explore and practice the application of different **accuracy metrics** used in both regression and classification problems. Measuring the performance of machine learning models is a crucial step in understanding how well a model generalizes to unseen data. By working through different types of accuracy measures, we aim to build an intuition for when and how each metric should be used.\n",
        "\n",
        "The dataset used in this assignment is the **Fashion MNIST** dataset, a popular benchmark in computer vision. It consists of grayscale images of 10 different types of clothing items. Although it is inherently a multi-class classification dataset, we will also simulate regression and binary classification tasks as needed for different parts of this assignment."
      ],
      "metadata": {
        "id": "1VLginpHcKzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Objective of the Assignment\n",
        "\n",
        "The main goals of this assignment are:\n",
        "\n",
        "- To gain hands-on experience with evaluating machine learning models using various **regression metrics**, including:\n",
        "  - Mean Squared Error (MSE)\n",
        "  - Mean Absolute Error (MAE)\n",
        "  - Mean Absolute Percentage Error (MAPE)\n",
        "  - R² Score\n",
        "\n",
        "- To understand and compute **binary classification accuracy metrics**, such as:\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1-Score\n",
        "\n",
        "- To evaluate performance in **multi-class classification tasks** using:\n",
        "  - Class-wise Precision and Recall\n",
        "  - Macro, Micro, and Weighted F1-Scores\n",
        "\n",
        "- To discuss the appropriate accuracy metric for a **multi-label classification problem** in the context of player statistics in football.\n",
        "\n",
        "Throughout the notebook, each section will include explanations of the purpose of the metric being calculated, the reasoning behind the steps taken, and reflections on what was learned in the process.\n"
      ],
      "metadata": {
        "id": "pjYyXaEXcR8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Dataset Overview\n",
        "\n",
        "For this assignment, we are using the **Fashion MNIST** dataset, a popular dataset for image classification tasks. It is a collection of grayscale images of clothing items, provided by Zalando, and designed to serve as a more challenging drop-in replacement for the original MNIST handwritten digit dataset.\n",
        "\n",
        "### Key Characteristics of the Fashion MNIST Dataset:\n",
        "\n",
        "- **Number of Classes**: 10\n",
        "- **Image Size**: 28 x 28 pixels\n",
        "- **Color Mode**: Grayscale (1 channel)\n",
        "- **Number of Training Samples**: 60,000\n",
        "- **Number of Test Samples**: 10,000\n",
        "\n",
        "Each image in the dataset represents one of the following clothing categories:\n",
        "\n",
        "| Label | Class Name        |\n",
        "|-------|-------------------|\n",
        "| 0     | T-shirt/top       |\n",
        "| 1     | Trouser           |\n",
        "| 2     | Pullover          |\n",
        "| 3     | Dress             |\n",
        "| 4     | Coat              |\n",
        "| 5     | Sandal            |\n",
        "| 6     | Shirt             |\n",
        "| 7     | Sneaker           |\n",
        "| 8     | Bag               |\n",
        "| 9     | Ankle boot        |\n",
        "\n",
        "The dataset is pre-split into a training set and a test set. This makes it convenient for experimenting with different machine learning models and accuracy metrics. In the upcoming sections, we will reshape and preprocess the data to suit different tasks such as regression, binary classification, and multi-class classification.\n"
      ],
      "metadata": {
        "id": "2nFVdW-jcpXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Tools and Libraries Used\n",
        "\n",
        "In this notebook, we will use several Python libraries that are widely adopted in the data science and machine learning communities. These tools help with data manipulation, model training, and performance evaluation.\n",
        "\n",
        "### Main Libraries Used:\n",
        "\n",
        "- **NumPy**:  \n",
        "  For efficient numerical computations and array manipulation.\n",
        "\n",
        "- **Matplotlib & Seaborn**:  \n",
        "  For visualizing the dataset and model performance.\n",
        "\n",
        "- **scikit-learn (sklearn)**:  \n",
        "  This is the main machine learning library used in this assignment. It provides:\n",
        "  - Tools to split datasets\n",
        "  - Built-in classification and regression models\n",
        "  - A variety of performance metrics such as MSE, MAE, Precision, Recall, F1-Score, and more\n",
        "\n",
        "- **TensorFlow/Keras**:  \n",
        "  Only used to load the Fashion MNIST dataset quickly and easily.\n",
        "\n",
        "### Why These Tools?\n",
        "\n",
        "These libraries offer a simple yet powerful interface for implementing machine learning pipelines, allowing us to focus on learning and applying concepts rather than low-level implementation details.\n",
        "\n",
        "We will explain the use of each tool at the point where it is used in the notebook."
      ],
      "metadata": {
        "id": "n10rbV9ac0r7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preprocessing\n",
        "\n",
        "Before applying any machine learning models or evaluating metrics, we need to load and prepare the dataset. This involves importing the dataset, inspecting its structure, and preparing it for various tasks such as regression, binary classification, and multi-class classification."
      ],
      "metadata": {
        "id": "aeBXwcw0dB3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Loading the Fashion MNIST Dataset\n",
        "\n",
        "In this section, we load the Fashion MNIST dataset using the `tensorflow.keras.datasets` module. The dataset is already split into training and testing sets, which makes it suitable for evaluating model performance without manual splitting.\n",
        "\n",
        "We also print the shape of the data to understand the structure."
      ],
      "metadata": {
        "id": "KhePS44ddEOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Print the shape of the training and test sets\n",
        "print(f\"X_train shape: {X_train.shape}\")   # (60000, 28, 28)\n",
        "print(f\"y_train shape: {y_train.shape}\")   # (60000,)\n",
        "print(f\"X_test shape: {X_test.shape}\")     # (10000, 28, 28)\n",
        "print(f\"y_test shape: {y_test.shape}\")     # (10000,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiZiGJpmdHc3",
        "outputId": "79e35c32-0c22-480a-c588-82011b209071"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_train shape: (60000, 28, 28)\n",
            "y_train shape: (60000,)\n",
            "X_test shape: (10000, 28, 28)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We successfully loaded the Fashion MNIST dataset, which contains 60,000 training samples and 10,000 test samples.\n",
        "- Each image is 28x28 pixels and grayscale (1 channel).\n",
        "- The labels (`y_train`, `y_test`) represent the clothing category, with values from 0 to 9.\n",
        "- These values will later be used for multi-class classification, and in some cases, transformed for binary classification or regression tasks.\n",
        "\n",
        "In the next steps, we will visualize and normalize this data to prepare it for use in machine learning models."
      ],
      "metadata": {
        "id": "Gs-jG_K7dPs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Visualizing the Data\n",
        "\n",
        "Before we proceed with preprocessing and modeling, it's important to **visualize** a few samples from the dataset. This helps us better understand the nature of the data we are working with.\n",
        "\n",
        "In this section, we display a few random images from the training set along with their corresponding labels to get a sense of what the Fashion MNIST dataset looks like."
      ],
      "metadata": {
        "id": "boUT_g1Rdb9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class labels for Fashion MNIST\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Plotting 15 random images from the training set\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(15):\n",
        "    idx = np.random.randint(0, len(X_train))\n",
        "    plt.subplot(3, 5, i + 1)\n",
        "    plt.imshow(X_train[idx], cmap='gray')\n",
        "    plt.title(class_names[y_train[idx]])\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "3m64GQwYdeec",
        "outputId": "15d5b723-591e-4091-b9e4-7e8e9348728f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We plotted 15 random samples from the training set.\n",
        "- Each image clearly represents a grayscale item of clothing from one of the 10 predefined categories.\n",
        "- This step confirms that the dataset is correctly loaded and that the labels align well with the visual data.\n",
        "\n",
        "Visualizing the dataset helps ensure there are no obvious issues and gives us insight into the variation within each class. In the next step, we will normalize the pixel values to prepare the data for training and evaluation."
      ],
      "metadata": {
        "id": "TguoKzDqdj41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Data Normalization and Reshaping\n",
        "\n",
        "Before feeding the data into any machine learning model, we need to preprocess it by **normalizing** and **reshaping** the input data.\n",
        "\n",
        "### Why Normalize?\n",
        "\n",
        "The original pixel values range from 0 to 255. Normalizing them to a range of [0, 1] helps:\n",
        "- Speed up training and convergence\n",
        "- Ensure all features contribute equally to the result\n",
        "\n",
        "### Why Reshape?\n",
        "\n",
        "Different models require different input formats:\n",
        "- For traditional machine learning models (like logistic regression), we **flatten** the 2D images into 1D vectors.\n",
        "- For deep learning models like CNNs, we **expand the dimensions** to include a channel axis.\n",
        "\n",
        "Here, we flatten the images for use in scikit-learn models."
      ],
      "metadata": {
        "id": "QyhOJ8N_dujF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to the range [0, 1]\n",
        "X_train_norm = X_train / 255.0\n",
        "X_test_norm = X_test / 255.0\n",
        "\n",
        "# Flatten 28x28 images to 784-dimensional vectors\n",
        "X_train_flat = X_train_norm.reshape(-1, 28 * 28)\n",
        "X_test_flat = X_test_norm.reshape(-1, 28 * 28)\n",
        "\n",
        "# Show the new shapes\n",
        "print(\"Normalized and flattened shapes:\")\n",
        "print(f\"X_train_flat shape: {X_train_flat.shape}\")  # (60000, 784)\n",
        "print(f\"X_test_flat shape: {X_test_flat.shape}\")    # (10000, 784)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87FUzn_4dzTd",
        "outputId": "5e4b80d7-29bc-4e6e-8be6-b24e35f140fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized and flattened shapes:\n",
            "X_train_flat shape: (60000, 784)\n",
            "X_test_flat shape: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We normalized all pixel values to the [0, 1] range.\n",
        "- We flattened the 28×28 images into 784-dimensional vectors so they can be used with scikit-learn models.\n",
        "- The resulting `X_train_flat` and `X_test_flat` are now ready for use in classification and regression models.\n",
        "\n",
        "In the next section, we will apply various models to generate predictions and compute the required accuracy metrics."
      ],
      "metadata": {
        "id": "hK0229Lnd2Z-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Splitting into Training and Testing Sets\n",
        "\n",
        "The Fashion MNIST dataset is already split into training and testing sets by default. However, for certain tasks—such as binary classification, multi-class classification, or regression—we might want to create a validation split or work with a smaller subset of the data for simplicity and speed.\n",
        "\n",
        "In this step, we ensure our training and test sets are in the correct format, and we optionally create a validation split using scikit-learn's `train_test_split`.\n",
        "\n",
        "> Note: For this assignment, we’ll continue using `X_train_flat` and `X_test_flat` as prepared in the previous step."
      ],
      "metadata": {
        "id": "n_x5vum0eH5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Optional: create a smaller subset of the training set for faster testing (e.g., 10,000 samples)\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(X_train_flat, y_train, test_size=50000, random_state=42)\n",
        "\n",
        "# Also create a validation split from the training subset if needed\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_sub, y_train_sub, test_size=0.2, random_state=42)\n",
        "\n",
        "# Show the shape of final datasets\n",
        "print(\"Shapes after optional re-splitting:\")\n",
        "print(f\"X_train_final shape: {X_train_final.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"X_test_flat shape: {X_test_flat.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rVjhxIgeNEB",
        "outputId": "adac029d-7d8e-43dc-8437-0a494043e3eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes after optional re-splitting:\n",
            "X_train_final shape: (8000, 784)\n",
            "X_val shape: (2000, 784)\n",
            "X_test_flat shape: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- The original dataset is already split into 60,000 training and 10,000 testing samples.\n",
        "- We optionally extracted a smaller subset (10,000 samples) from the training data for faster experimentation.\n",
        "- From this subset, we created a validation split (80% training, 20% validation).\n",
        "- These sets (`X_train_final`, `X_val`, `X_test_flat`) will be used for training and evaluating different models.\n",
        "\n",
        "Now that the data is prepared, we can move on to evaluating regression accuracy metrics."
      ],
      "metadata": {
        "id": "VxA68b8PePmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Regression Accuracy Metrics\n",
        "\n",
        "Since Fashion MNIST is primarily a classification dataset, we do not have direct regression targets. To practice regression accuracy metrics, we simulate a regression problem using this dataset."
      ],
      "metadata": {
        "id": "jV-VcBjJecuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Simulating Regression Problem\n",
        "\n",
        "To create a regression problem from this classification dataset, we will predict a continuous target derived from the labels. For example:\n",
        "\n",
        "- Use the numeric labels themselves (0 to 9) as a regression target.\n",
        "- Alternatively, predict the **average pixel intensity** of each image as a continuous target.\n",
        "\n",
        "Here, we will simulate regression by trying to predict the numeric label (0 to 9) as a continuous variable. Although this is not a typical regression task, it allows us to compute regression metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and R² score.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. Use the flattened images (`X_train_flat`, `X_test_flat`) as input features.\n",
        "2. Use the numeric labels (`y_train`, `y_test`) as continuous regression targets.\n",
        "3. Train a simple regression model (e.g., Linear Regression) on this data.\n",
        "4. Calculate and analyze regression metrics based on model predictions.\n",
        "\n",
        "This approach helps us practice measuring regression metrics even on a classification dataset."
      ],
      "metadata": {
        "id": "Ds_xgvTIeif7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Define features and continuous targets for regression simulation\n",
        "X_train_reg = X_train_flat\n",
        "y_train_reg = y_train.astype(float)  # numeric labels as continuous values\n",
        "\n",
        "X_test_reg = X_test_flat\n",
        "y_test_reg = y_test.astype(float)\n",
        "\n",
        "# Train a simple Linear Regression model\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_reg = regressor.predict(X_test_reg)\n",
        "\n",
        "# Show a few predictions alongside true values\n",
        "for i in range(5):\n",
        "    print(f\"True label: {y_test_reg[i]}, Predicted value: {y_pred_reg[i]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH12ehMpemIh",
        "outputId": "6cbc0ea3-33da-45d4-928b-1a0265404f22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label: 9.0, Predicted value: 7.57\n",
            "True label: 2.0, Predicted value: 2.72\n",
            "True label: 1.0, Predicted value: 0.60\n",
            "True label: 1.0, Predicted value: 0.84\n",
            "True label: 6.0, Predicted value: 3.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We transformed the classification labels into continuous values for regression.\n",
        "- Trained a simple Linear Regression model to predict these values.\n",
        "- This simulation allows us to calculate and understand regression metrics on the dataset.\n",
        "- The predicted values are continuous and approximate the numeric labels, showing the model's regression output.\n",
        "\n",
        "Next, we will calculate the common regression accuracy metrics to evaluate this model."
      ],
      "metadata": {
        "id": "OJ-3IBKGepgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Calculating Mean Squared Error (MSE)\n",
        "\n",
        "Mean Squared Error (MSE) is one of the most common metrics for regression problems. It measures the average squared difference between the predicted values and the actual values.\n",
        "\n",
        "$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $y_i$ is the true value\n",
        "- $\\hat{y}_i$ is the predicted value\n",
        "- $n$ is the number of samples\n",
        "\n",
        "MSE gives a higher penalty to larger errors due to the squaring, making it sensitive to outliers.\n",
        "\n",
        "We will calculate the MSE between our regression model’s predicted labels and the true numeric labels.\n"
      ],
      "metadata": {
        "id": "eXKWjHOce1lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeARgWyce1IE",
        "outputId": "c2a11a6b-120d-4212-f456-c14e5b14afee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.9684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We computed the Mean Squared Error to quantify the average squared difference between predicted and true labels.\n",
        "- A lower MSE indicates better regression performance.\n",
        "- In this simulated regression task, MSE helps us understand how close our model's predictions are to the actual class labels treated as continuous values.\n",
        "\n",
        "Next, we will calculate the Mean Absolute Error (MAE) to see another perspective on regression error."
      ],
      "metadata": {
        "id": "O6BMlRxMfI4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Calculating Mean Absolute Error (MAE)\n",
        "\n",
        "Mean Absolute Error (MAE) measures the average magnitude of the errors between predicted values and actual values without considering their direction. It is calculated as the average of the absolute differences:\n",
        "\n",
        "$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $y_i$ is the true value\n",
        "- $\\hat{y}_i$ is the predicted value\n",
        "- $n$ is the number of samples\n",
        "\n",
        "Unlike MSE, MAE treats all errors equally and is less sensitive to outliers.\n",
        "\n",
        "We will calculate MAE to get an intuitive sense of how far, on average, our predictions are from the true numeric labels.\n"
      ],
      "metadata": {
        "id": "wZSyrjDofUCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUxaPftRfWaV",
        "outputId": "f2f5f118-8d87-40c7-b1d5-931be520b5b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1.0222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We computed the Mean Absolute Error to measure the average absolute difference between predicted and true labels.\n",
        "- MAE provides an easy-to-interpret error metric in the same units as the target.\n",
        "- Comparing MAE with MSE gives us insight into the distribution of errors (e.g., whether large errors heavily affect MSE).\n",
        "\n",
        "Next, we will calculate the Mean Absolute Percentage Error (MAPE) to understand relative error percentages."
      ],
      "metadata": {
        "id": "3DL7huzRffAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Calculating Mean Absolute Percentage Error (MAPE)\n",
        "\n",
        "Mean Absolute Percentage Error (MAPE) expresses the error as a percentage of the true values. It is calculated as:\n",
        "\n",
        "$\n",
        "\\text{MAPE} = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $y_i$ is the true value\n",
        "- $\\hat{y}_i$ is the predicted value\n",
        "- $n$ is the number of samples\n",
        "\n",
        "MAPE provides an intuitive percentage-based measure of prediction accuracy. However, it can be problematic when true values are zero or close to zero, causing division by zero or large percentage errors.\n",
        "\n",
        "In our case, since the labels range from 0 to 9, MAPE might be unstable for label 0. To handle this, we will add a small epsilon value to avoid division by zero."
      ],
      "metadata": {
        "id": "l1dLVmHrfozs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out zero true labels to avoid division by zero\n",
        "non_zero_indices = y_test_reg != 0\n",
        "\n",
        "# Calculate MAPE only on non-zero true labels\n",
        "mape_filtered = np.mean(np.abs((y_test_reg[non_zero_indices] - y_pred_reg[non_zero_indices]) / y_test_reg[non_zero_indices])) * 100\n",
        "print(f\"Mean Absolute Percentage Error (MAPE) excluding zeros: {mape_filtered:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LVS2RsyfxKz",
        "outputId": "17aee3d9-8b9d-40a7-d32d-4c648b8b8c17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error (MAPE) excluding zeros: 25.5658%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We calculated MAPE to express the regression error as a percentage relative to the true labels.\n",
        "- This metric is useful for understanding the error in relative terms, which can be more interpretable in some contexts.\n",
        "- Due to zero labels, we added a small epsilon to avoid division by zero.\n",
        "- High MAPE indicates less accurate predictions in relative terms, especially for smaller true values.\n",
        "\n",
        "Next, we will calculate the R² Score to measure how well our regression model explains the variance in the data."
      ],
      "metadata": {
        "id": "Mr8c4-E8f2rV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. Calculating R² Score\n",
        "\n",
        "The R² Score, also known as the coefficient of determination, measures how well the regression predictions approximate the real data points. It is defined as:\n",
        "\n",
        "$R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$\n",
        "\n",
        "Where:\n",
        "- $y_i$ are the true values\n",
        "- $\\hat{y}_i$ are the predicted values\n",
        "- $\\bar{y}$ is the mean of the true values\n",
        "- $n$ is the number of samples\n",
        "\n",
        "An $R^2$ score of 1 indicates perfect predictions, while 0 means the model does no better than simply predicting the mean of the target values. Negative values indicate the model performs worse than that.\n",
        "\n",
        "We will calculate the $R^2$ score to assess how well our regression predictions explain the variance in the true labels."
      ],
      "metadata": {
        "id": "0gp6QO75geio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R^2 Score\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8S7dgLpgiXn",
        "outputId": "2ab3c2c7-8821-44fc-9abb-034d0becc053"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.7614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- The $R^2$ score tells us how much of the variance in the true labels is explained by the predicted labels.\n",
        "- A higher $R^2$ value (closer to 1) indicates better predictive performance.\n",
        "- Negative or low values imply poor prediction quality.\n",
        "- This metric complements MSE and MAE by providing a normalized measure of prediction accuracy.\n",
        "\n",
        "Next, we will move on to Binary Classification Accuracy Metrics."
      ],
      "metadata": {
        "id": "hcuCCJWkgh4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Binary Classification Accuracy Metrics\n",
        "\n",
        "In this section, we focus on measuring the accuracy metrics commonly used for binary classification problems. Since the Fashion MNIST dataset is multi-class, we will convert it into a binary classification task.\n",
        "\n",
        "**Note:** We will classify whether the label is 0 (e.g., \"T-shirt/top\") or not, turning the problem into a binary classification task."
      ],
      "metadata": {
        "id": "QlAhidSxg3Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Simulating a Binary Classification Task\n",
        "\n",
        "To simulate a binary classification problem, we will:\n",
        "- Convert the original multi-class labels into binary labels:\n",
        "  - Class 1 (positive): samples where label $=$ 0\n",
        "  - Class 0 (negative): samples where label $\\neq$ 0\n",
        "- Generate random predictions for the binary classes to demonstrate the calculation of binary classification metrics.\n",
        "\n",
        "This setup allows us to practice calculating metrics like Precision, Recall, and F1-Score in a binary classification context."
      ],
      "metadata": {
        "id": "t8eAgoAhg5d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Convert multi-class labels to binary: 1 if label==0, else 0\n",
        "y_test_binary = (y_test == 0).astype(int)\n",
        "\n",
        "# Generate random binary predictions (for demonstration)\n",
        "np.random.seed(42)  # for reproducibility\n",
        "y_pred_binary = np.random.randint(0, 2, size=y_test_binary.shape)\n",
        "\n",
        "print(f\"Sample of true binary labels: {y_test_binary[:10]}\")\n",
        "print(f\"Sample of predicted binary labels: {y_pred_binary[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTlBq0S-hCBW",
        "outputId": "94db4286-d3d8-409f-fe21-749445efac59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of true binary labels: [0 0 0 0 0 0 0 0 0 0]\n",
            "Sample of predicted binary labels: [0 1 0 0 0 1 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We simplified the multi-class classification into a binary problem by focusing on whether a sample belongs to class 0 or not.\n",
        "- Random binary predictions were generated to demonstrate how binary classification metrics are calculated.\n",
        "- This approach prepares us for the upcoming calculation of precision, recall, and F1-score.\n",
        "\n",
        "Next, we will calculate the precision metric for this binary classification task."
      ],
      "metadata": {
        "id": "I0UHZyDohFpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Calculating Precision\n",
        "\n",
        "Precision is the ratio of correctly predicted positive observations to the total predicted positives. It answers the question:\n",
        "\n",
        "**“Of all the samples predicted as positive, how many were actually positive?”**\n",
        "\n",
        "The formula for precision is:\n",
        "\n",
        "$ \\text{Precision} = \\frac{TP}{TP + FP} $\n",
        "\n",
        "Where:\n",
        "- $TP$ = True Positives\n",
        "- $FP$ = False Positives\n",
        "\n",
        "Precision is particularly important when the cost of false positives is high.\n",
        "\n",
        "We will calculate precision for our binary classification problem using the true and predicted labels."
      ],
      "metadata": {
        "id": "6luZUuWNhYLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision\n",
        "precision = precision_score(y_test_binary, y_pred_binary)\n",
        "print(f\"Precision: {precision:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tamR_hNChdnR",
        "outputId": "54c702a8-5974-40ea-9967-b0363b3a3c06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We computed precision to understand how accurate our model’s positive predictions are.\n",
        "- A high precision means that when the model predicts a positive, it is usually correct.\n",
        "- This metric is crucial in scenarios where false positives can cause significant problems.\n",
        "- Since we used random predictions here, the precision value might not be meaningful but serves as a demonstration.\n",
        "\n",
        "Next, we will calculate recall for this binary classification task."
      ],
      "metadata": {
        "id": "IkyOtSFHhbr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Calculating Recall\n",
        "\n",
        "Recall, also known as Sensitivity or True Positive Rate, measures the ratio of correctly predicted positive observations to all actual positives. It answers the question:\n",
        "\n",
        "**“Of all the actual positive samples, how many did the model correctly identify?”**\n",
        "\n",
        "The formula for recall is:\n",
        "\n",
        "$ \\text{Recall} = \\frac{TP}{TP + FN} $\n",
        "\n",
        "Where:\n",
        "- $TP$ = True Positives\n",
        "- $FN$ = False Negatives\n",
        "\n",
        "Recall is especially important in cases where missing positive cases (false negatives) is costly.\n",
        "\n",
        "We will calculate recall for our binary classification problem using the true and predicted labels."
      ],
      "metadata": {
        "id": "Zw07WtGuhly0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Recall\n",
        "recall = recall_score(y_test_binary, y_pred_binary)\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm2jpEn1hoz-",
        "outputId": "5c80ec07-65f8-4c44-cb3f-e566aa806e00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.4930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We calculated recall to evaluate the model’s ability to identify all positive samples.\n",
        "- High recall means the model successfully detects most of the positive cases.\n",
        "- This metric is vital in scenarios where failing to detect a positive case has serious consequences.\n",
        "- Since predictions are random here, recall values are just for demonstration.\n",
        "\n",
        "Next, we will calculate the F1-Score, which balances precision and recall."
      ],
      "metadata": {
        "id": "rSKATOJ2hsHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. Calculating F1-Score\n",
        "\n",
        "The F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. It is especially useful when you need to seek a balance between precision and recall, or when you have an uneven class distribution.\n",
        "\n",
        "The formula for F1-Score is:\n",
        "\n",
        "$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $\n",
        "\n",
        "We will calculate the F1-Score for our binary classification task using the true and predicted labels."
      ],
      "metadata": {
        "id": "ofp06QDSh23s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1-Score\n",
        "f1 = f1_score(y_test_binary, y_pred_binary)\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "n_uhWl78h2J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- The F1-Score combines precision and recall into a single measure of model performance.\n",
        "- It is especially helpful when the dataset is imbalanced or when both false positives and false negatives are important.\n",
        "- A high F1-Score indicates a good balance between precision and recall.\n",
        "- Here, the value serves as a demonstration since predictions are random.\n",
        "\n",
        "Next, we will move on to Multi-class Classification Accuracy Metrics."
      ],
      "metadata": {
        "id": "MrdIW9o1h3QF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Multi-class Classification Accuracy Metrics\n",
        "\n",
        "In this section, we will handle the original multi-class nature of the Fashion MNIST dataset and evaluate classification metrics specific to multi-class problems.\n",
        "\n",
        "We will train a simple multi-class classifier and then calculate metrics such as Precision and Recall for each class, along with Macro, Weighted, and Micro-averaged F1-Scores.\n"
      ],
      "metadata": {
        "id": "dd_JiYJoiIWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Training a Multi-class Classifier\n",
        "\n",
        "To evaluate multi-class metrics, we first need a trained classifier. Here, we will train a simple Logistic Regression model on the flattened Fashion MNIST images.\n",
        "\n",
        "Steps:\n",
        "- Flatten the images from 28x28 to a 784-length vector.\n",
        "- Train the Logistic Regression model on the training data.\n",
        "- Predict labels on the test set."
      ],
      "metadata": {
        "id": "4osXJKjziLqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Flatten the images\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "X_train_flat = X_train_flat / 255.0\n",
        "X_test_flat = X_test_flat / 255.0\n",
        "\n",
        "# Train Logistic Regression classifier (multi-class by default)\n",
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf.fit(X_train_flat, y_train)\n",
        "\n",
        "# Predict test labels\n",
        "y_pred_multi = clf.predict(X_test_flat)\n",
        "\n",
        "print(\"Training complete. Sample predictions:\")\n",
        "print(y_pred_multi[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IywgM9DliMUv",
        "outputId": "f849fb1b-cdeb-4691-bf58-d2bd0fecebb9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete. Sample predictions:\n",
            "[9 2 1 1 6 1 4 6 5 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We transformed the image data into a suitable format for traditional machine learning algorithms.\n",
        "- Logistic Regression was trained as a baseline multi-class classifier.\n",
        "- This prepares us to compute multi-class accuracy metrics such as Precision and Recall for each class.\n",
        "- The model's predictions will be used in the next section to calculate detailed evaluation metrics."
      ],
      "metadata": {
        "id": "7T5aBp3JiQVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Precision for Each Class\n",
        "\n",
        "Precision in a multi-class setting is calculated for each class individually. It measures how many of the samples predicted as a certain class are actually from that class.\n",
        "\n",
        "In other words, for each class $i$:\n",
        "\n",
        "$ \\text{Precision}_i = \\frac{TP_i}{TP_i + FP_i} $\n",
        "\n",
        "Where:\n",
        "- $TP_i$ = True Positives for class $i$\n",
        "- $FP_i$ = False Positives for class $i$\n",
        "\n",
        "We will calculate and display precision for each of the 10 classes in the Fashion MNIST dataset using the model predictions.\n"
      ],
      "metadata": {
        "id": "Z195duOPil6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Calculate precision for each class (average=None returns per-class metrics)\n",
        "precision_per_class = precision_score(y_test, y_pred_multi, average=None)\n",
        "\n",
        "# Display precision for each class\n",
        "for i, precision in enumerate(precision_per_class):\n",
        "    print(f\"Precision for class {i}: {precision:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTS323TAipGb",
        "outputId": "179dba0f-27d9-4ef0-f41e-f41703599696"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for class 0: 0.7990\n",
            "Precision for class 1: 0.9706\n",
            "Precision for class 2: 0.7247\n",
            "Precision for class 3: 0.8293\n",
            "Precision for class 4: 0.7413\n",
            "Precision for class 5: 0.9455\n",
            "Precision for class 6: 0.6239\n",
            "Precision for class 7: 0.9093\n",
            "Precision for class 8: 0.9303\n",
            "Precision for class 9: 0.9509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We computed precision for each class separately to understand how well the model predicts each category.\n",
        "- This detailed analysis helps identify classes where the model performs well or struggles.\n",
        "- Precision values closer to 1 indicate accurate positive predictions for that class.\n",
        "- This metric is useful to analyze model strengths and weaknesses on a per-class basis."
      ],
      "metadata": {
        "id": "76kpiQ4LirU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3. Recall for Each Class\n",
        "\n",
        "Recall in a multi-class setting is calculated for each class individually. It measures how many of the actual samples of a certain class were correctly identified by the model.\n",
        "\n",
        "For each class $i$:\n",
        "\n",
        "$ \\text{Recall}_i = \\frac{TP_i}{TP_i + FN_i} $\n",
        "\n",
        "Where:\n",
        "- $TP_i$ = True Positives for class $i$\n",
        "- $FN_i$ = False Negatives for class $i$\n",
        "\n",
        "We will calculate and display recall for each of the 10 classes in the Fashion MNIST dataset using the model predictions.\n"
      ],
      "metadata": {
        "id": "U5XEMG7-i86a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Calculate recall for each class (average=None returns per-class metrics)\n",
        "recall_per_class = recall_score(y_test, y_pred_multi, average=None)\n",
        "\n",
        "# Display recall for each class\n",
        "for i, recall in enumerate(recall_per_class):\n",
        "    print(f\"Recall for class {i}: {recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQwdUqdjjDi8",
        "outputId": "ce62ec6d-bc91-4e54-9ecd-c4b8fe4d8716"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for class 0: 0.8030\n",
            "Recall for class 1: 0.9570\n",
            "Recall for class 2: 0.7370\n",
            "Recall for class 3: 0.8600\n",
            "Recall for class 4: 0.7650\n",
            "Recall for class 5: 0.9200\n",
            "Recall for class 6: 0.5690\n",
            "Recall for class 7: 0.9420\n",
            "Recall for class 8: 0.9350\n",
            "Recall for class 9: 0.9480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- We computed recall for each class separately to understand how well the model identifies all samples of each category.\n",
        "- This helps in identifying classes where the model may be missing many true positives.\n",
        "- Recall values closer to 1 indicate most actual samples of that class were correctly detected.\n",
        "- Alongside precision, recall provides a fuller picture of the model’s performance per class."
      ],
      "metadata": {
        "id": "gEv5jqX0jMaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4. F1-Score (Macro, Weighted, Micro Averaging)\n",
        "\n",
        "The F1-Score is the harmonic mean of precision and recall, balancing these two important metrics.\n",
        "\n",
        "In multi-class classification, we calculate F1-Score using different averaging methods:\n",
        "\n",
        "- **Macro Averaging:** Calculates the F1-Score independently for each class and then takes the average. Treats all classes equally.\n",
        "  \n",
        "- **Weighted Averaging:** Calculates the F1-Score for each class and takes the average weighted by the number of true instances per class. Accounts for class imbalance.\n",
        "  \n",
        "- **Micro Averaging:** Aggregates the contributions of all classes to compute the average metric globally. It essentially calculates metrics by counting total true positives, false negatives, and false positives.\n",
        "\n",
        "These different averages give insights from multiple perspectives, especially in imbalanced datasets.\n",
        "\n",
        "We will calculate and compare Macro, Weighted, and Micro averaged F1-Scores using the predicted and true labels."
      ],
      "metadata": {
        "id": "Ny40yLNIjPPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate F1-Scores with different averaging methods\n",
        "f1_macro = f1_score(y_test, y_pred_multi, average='macro')\n",
        "f1_weighted = f1_score(y_test, y_pred_multi, average='weighted')\n",
        "f1_micro = f1_score(y_test, y_pred_multi, average='micro')\n",
        "\n",
        "print(f\"Macro-averaged F1-Score: {f1_macro:.4f}\")\n",
        "print(f\"Weighted-averaged F1-Score: {f1_weighted:.4f}\")\n",
        "print(f\"Micro-averaged F1-Score: {f1_micro:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50RPZ4V5jShU",
        "outputId": "1c079e87-f4d0-4144-beb2-35f080a1159b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-averaged F1-Score: 0.8428\n",
            "Weighted-averaged F1-Score: 0.8428\n",
            "Micro-averaged F1-Score: 0.8436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we did and learned:\n",
        "\n",
        "- Macro F1-Score treats all classes equally, useful when you want to assess overall performance without considering class imbalance.\n",
        "- Weighted F1-Score accounts for the number of samples per class, giving a more realistic performance measure when classes are imbalanced.\n",
        "- Micro F1-Score aggregates contributions globally and is sensitive to the most frequent classes.\n",
        "- Comparing these scores helps us understand how the model performs across different classes and how class distribution affects evaluation.\n",
        "- These metrics provide a comprehensive understanding of model quality on multi-class tasks."
      ],
      "metadata": {
        "id": "QLkaJSRijVih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Multi-label Classification Discussion\n",
        "\n",
        "Multi-label classification differs from multi-class classification in that each sample can belong to multiple classes simultaneously, rather than exactly one class."
      ],
      "metadata": {
        "id": "SKVycoSKjm5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. Problem Description in Football Domain\n",
        "\n",
        "Consider a multi-label classification problem in football where each player can have multiple attributes from the following classes:\n",
        "\n",
        "- **Class 1:** The player has played for the national team before.\n",
        "- **Class 2:** The player had previous history of heart problems.\n",
        "- **Class 3:** The player had knee injuries before.\n",
        "- **Class 4:** The player has been the captain of the team in the past.\n",
        "\n",
        "In this problem, a single player (sample) may belong to none, one, or multiple of these classes simultaneously. For example, a player could have both heart problems and be a former captain, or might have no history of injury but played for the national team.\n",
        "\n",
        "This problem cannot be solved with traditional multi-class classification, where each sample belongs to exactly one class, but requires specialized multi-label classification techniques and metrics.\n",
        "\n",
        "In the next subsection, we will discuss the most appropriate accuracy metric to evaluate such multi-label classification models and explain why.\n",
        "\n",
        "### What we understood:\n",
        "\n",
        "- Multi-label classification allows for overlapping classes per sample.\n",
        "- The football player example highlights the need for metrics that can evaluate multiple simultaneous labels.\n",
        "- Understanding the problem setup is crucial before selecting the correct evaluation metrics."
      ],
      "metadata": {
        "id": "5bk7KAvLjsMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Suitable Accuracy Metric and Justification\n",
        "\n",
        "For multi-label classification problems like the football player example, where each player can belong to multiple classes simultaneously, traditional single-label accuracy metrics (like accuracy, precision, or recall for single classes) are insufficient.\n",
        "\n",
        "The most appropriate accuracy metric in this context is **Hamming Loss** or **Subset Accuracy**, but the commonly used and intuitive choice is:\n",
        "\n",
        "#### **Hamming Loss**\n",
        "\n",
        "- **Definition:**  \n",
        "  Hamming Loss calculates the fraction of labels that are incorrectly predicted, averaged over all labels and samples. It accounts for both false positives and false negatives across all labels.\n",
        "\n",
        "- **Formula:**  \n",
        "  $$\n",
        "  \\text{Hamming Loss} = \\frac{1}{N \\times L} \\sum_{i=1}^{N} \\sum_{j=1}^{L} \\mathbf{1}[\\hat{y}_{ij} \\neq y_{ij}]\n",
        "  $$  \n",
        "  where $N$ is the number of samples, $L$ is the number of labels, $y_{ij}$ is the true label, and $\\hat{y}_{ij}$ is the predicted label.\n",
        "\n",
        "- **Why Hamming Loss?**  \n",
        "  - It treats each label independently, allowing partial credit when some labels are predicted correctly while others are not.\n",
        "  - It penalizes both types of errors (missing a relevant label or predicting an irrelevant label).\n",
        "  - Suitable for multi-label problems where partial correctness matters.\n",
        "\n",
        "#### Other metrics to consider:\n",
        "\n",
        "- **Subset Accuracy:** Strict metric that requires exact match of all labels for a sample; often too harsh in multi-label problems.\n",
        "- **Precision, Recall, and F1-Score (Macro, Micro):** Can be adapted for multi-label by averaging over labels, but may not capture label-wise errors as clearly as Hamming Loss.\n",
        "\n",
        "**In summary**, for the football player classification problem, **Hamming Loss** is the most appropriate metric as it accurately measures how well the model predicts multiple labels per player, reflecting the partial correctness of predictions.\n",
        "\n",
        "### What we learned:\n",
        "\n",
        "- Multi-label problems require different metrics than single-label classification.\n",
        "- Hamming Loss balances penalizing false positives and negatives across multiple labels.\n",
        "- Choosing the right metric is critical to properly evaluate and improve multi-label classifiers.\n"
      ],
      "metadata": {
        "id": "wVYrReBDjxTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion"
      ],
      "metadata": {
        "id": "v6S7ANGnkEtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. Summary of Observations\n",
        "\n",
        "In this assignment, we explored various accuracy measures across regression, binary classification, multi-class classification, and multi-label classification contexts using the Fashion MNIST dataset and simulated problems.\n",
        "\n",
        "Key observations include:\n",
        "\n",
        "- **Regression Metrics:**  \n",
        "  We calculated Mean Squared Error (MSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and the R² score on a simulated regression task. These metrics gave us insights into the average magnitude of errors, percentage errors, and the proportion of variance explained by the model.\n",
        "\n",
        "- **Binary Classification Metrics:**  \n",
        "  By converting the problem into a binary classification (detecting class 0 vs. others), we calculated Precision, Recall, and F1-Score. These metrics helped us understand the balance between correctly identifying positive samples and avoiding false alarms.\n",
        "\n",
        "- **Multi-class Classification Metrics:**  \n",
        "  Using a simple classifier on the full multi-class Fashion MNIST dataset, we measured precision and recall for each class individually, and computed Macro, Weighted, and Micro averaged F1-Scores. These evaluations highlighted how model performance can vary across different classes and how averaging strategies affect the overall performance measure.\n",
        "\n",
        "- **Multi-label Classification Discussion:**  \n",
        "  We discussed a football domain multi-label classification problem where each sample can belong to multiple classes simultaneously. We identified **Hamming Loss** as the most suitable metric to accurately capture the performance of such multi-label models, as it accounts for both false positives and false negatives on a per-label basis.\n",
        "\n",
        "- **General Learnings:**  \n",
        "  - Selecting the right accuracy metric depends strongly on the nature of the problem (regression vs classification, single-label vs multi-label).\n",
        "  - Understanding these metrics enables better interpretation of model performance and guides improvements.\n",
        "  - Clear explanations and contextual understanding are critical when presenting results.\n",
        "\n",
        "This assignment reinforced our understanding of evaluation metrics and their applications in different machine learning problem settings."
      ],
      "metadata": {
        "id": "uQDGdO4BkOIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2. What I Learned\n",
        "\n",
        "Throughout this assignment, I gained valuable insights into the importance and nuances of different accuracy metrics in machine learning:\n",
        "\n",
        "- **Understanding Metric Suitability:**  \n",
        "  I learned that the choice of accuracy metric depends on the problem type. Metrics that work well for regression may not be appropriate for classification, and within classification, different metrics serve different purposes depending on whether the problem is binary, multi-class, or multi-label.\n",
        "\n",
        "- **Regression Metrics:**  \n",
        "  I understood how metrics like MSE, MAE, MAPE, and R² provide different perspectives on prediction errors — from average squared errors to percentage errors and variance explained.\n",
        "\n",
        "- **Classification Metrics:**  \n",
        "  For binary and multi-class classification, I learned how precision, recall, and F1-score complement each other by measuring different aspects of classification performance, such as the ability to detect positives and the trade-off between precision and recall.\n",
        "\n",
        "- **Multi-label Classification Challenges:**  \n",
        "  I realized that multi-label problems require specialized metrics like Hamming Loss to correctly evaluate model performance because each sample can belong to multiple classes simultaneously.\n",
        "\n",
        "- **Importance of Clear Explanations:**  \n",
        "  Providing explanations alongside code helped deepen my understanding and ensured I could communicate the reasoning behind each step clearly.\n",
        "\n",
        "Overall, this assignment strengthened my ability to evaluate machine learning models appropriately and highlighted the importance of selecting metrics aligned with the specific problem context."
      ],
      "metadata": {
        "id": "xsGy99xpkQ81"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"Times New Roman\" size=5>\n",
        "<div dir=rtl align=\"center\">\n",
        "<font face=\"Times New Roman\" size=5>\n",
        "</font>\n",
        "<br>\n",
        "<img src=\"https://static.tildacdn.one/tild3639-3035-4131-a461-363737393037/noroot.png\" alt=\"University Logo\" width=\"400\" height=\"224\">\n",
        "<br>\n",
        "<font face=\"Times New Roman\" size=5 align=center>\n",
        "Sharif University of Technology\n",
        "<br>\n",
        "Electrical Engineering Department\n",
        "</font>\n",
        "<br>\n",
        "<font size=6>\n",
        "Assignment 9: Neural Networks\n",
        "</font>\n",
        "<br>\n",
        "<font size=4>\n",
        "Zahra Helalizadeh 400102193\n",
        "<br>\n",
        "</font>\n",
        "<font size=4>\n",
        "Spring 2025\n",
        "<br>\n",
        "</font>\n",
        "<font face=\"Times New Roman\" size=4>\n",
        "</font>\n",
        "</div></font>"
      ],
      "metadata": {
        "id": "5CjJXcFSh0l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup and Data Preprocessing\n",
        "\n",
        "## 1.1 Import Libraries\n",
        "\n",
        "In this section, we import the necessary Python libraries that we will use throughout the notebook.\n",
        "\n",
        "- `numpy`: for numerical operations and array manipulation.\n",
        "- `matplotlib.pyplot`: for visualizing the data and training results.\n",
        "- `seaborn`: for more aesthetic and informative data visualizations.\n",
        "- `sklearn`: for preprocessing, train-test split, metrics, and Scikit-Learn models.\n",
        "- `tensorflow.keras`: for building and training neural networks using Keras.\n",
        "- `torch` and `torchvision`: for building and training neural networks using PyTorch."
      ],
      "metadata": {
        "id": "fXuBtB2xkayl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vc4CQ_UChzIH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, r2_score\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import a variety of machine learning libraries to allow us to work with different frameworks.\n",
        "\n",
        "Scikit-Learn will be used for building and evaluating simple multilayer perceptron models.  \n",
        "TensorFlow/Keras will be used for building 4-layer feedforward and recurrent neural networks.  \n",
        "PyTorch will be used for implementing more flexible architectures and manual training loops.\n",
        "\n",
        "`torchvision` is included to help load and preprocess the Fashion MNIST dataset in PyTorch.\n",
        "\n",
        "All other libraries are standard tools for scientific computing and data visualization in Python."
      ],
      "metadata": {
        "id": "MeQWbDZkkfgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Load the Fashion MNIST Dataset\n",
        "\n",
        "In this section, we load the Fashion MNIST dataset. This dataset is a collection of 70,000 grayscale images of fashion products from 10 different categories. Each image is 28x28 pixels in size.\n",
        "\n",
        "The dataset is divided into 60,000 training samples and 10,000 test samples. Each image belongs to one of the following 10 classes:\n",
        "\n",
        "0: T-shirt/top  \n",
        "1: Trouser  \n",
        "2: Pullover  \n",
        "3: Dress  \n",
        "4: Coat  \n",
        "5: Sandal  \n",
        "6: Shirt  \n",
        "7: Sneaker  \n",
        "8: Bag  \n",
        "9: Ankle boot\n",
        "\n",
        "We will use the Keras API to load the dataset in NumPy array format."
      ],
      "metadata": {
        "id": "-yad3F9ikrIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion MNIST dataset from Keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the training and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "e0ALAbCsksJW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the shape of the training and test data to better understand its structure."
      ],
      "metadata": {
        "id": "QcMOmWVakxAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86nJTVO_kzc5",
        "outputId": "a93c7e8f-3c6d-4817-9e09-8f99569773d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28)\n",
            "Training labels shape: (60000,)\n",
            "Test data shape: (10000, 28, 28)\n",
            "Test labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image has shape (28, 28), and each label is an integer from 0 to 9.  \n",
        "There are 60,000 training images and 10,000 test images.  \n",
        "We will use a portion of the training set for validation later, and we will reshape and normalize the data in the next step."
      ],
      "metadata": {
        "id": "ET-1svJXk192"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Preprocess the Data\n",
        "\n",
        "Before feeding the data into a neural network, we need to preprocess it properly. Neural networks work better when the input values are in a consistent scale, especially in the range [0, 1].\n",
        "\n",
        "Therefore, we normalize the pixel values of the images by dividing them by 255, which is the maximum possible value of a pixel in grayscale.\n",
        "\n",
        "Also, feedforward neural networks require 1D input vectors, so we flatten the 28x28 images into vectors of size 784.\n",
        "\n",
        "Finally, we split the original training set into 80% training and 20% validation/test for evaluation purposes."
      ],
      "metadata": {
        "id": "5WadQreqlIT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Flatten the images for feedforward networks\n",
        "x_train_flat = x_train.reshape(-1, 28 * 28)\n",
        "x_test_flat = x_test.reshape(-1, 28 * 28)"
      ],
      "metadata": {
        "id": "2du-qcG3lKdt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we split the training data into a training set and a validation set. This helps us evaluate the performance of our models on unseen data before we use the final test set."
      ],
      "metadata": {
        "id": "Fofs2F05lMmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into 80% training and 20% validation\n",
        "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
        "    x_train_flat, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", x_train_final.shape)\n",
        "print(\"Validation set shape:\", x_val.shape)\n",
        "print(\"Test set shape:\", x_test_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Reu3JdR5lPY9",
        "outputId": "02f66152-65cd-430f-b010-36a487251533"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (48000, 784)\n",
            "Validation set shape: (12000, 784)\n",
            "Test set shape: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, all input features are scaled between 0 and 1 and reshaped into vectors of length 784.  \n",
        "This format is now suitable for feedforward neural networks, which expect fixed-size vector inputs.  \n",
        "The training set is now 48,000 samples, the validation set is 12,000 samples, and the test set remains at 10,000 samples."
      ],
      "metadata": {
        "id": "qAKINMAZlSYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Baseline MLP with Scikit-Learn\n",
        "\n",
        "### 2.1 Build a Multilayer Perceptron Classifier\n",
        "\n",
        "In this section, we build a baseline multilayer perceptron (MLP) classifier using Scikit-Learn's `MLPClassifier`.\n",
        "\n",
        "This model will serve as a starting point to evaluate how well a simple feedforward neural network can classify the Fashion MNIST images.\n",
        "\n",
        "We will use the flattened and normalized training data prepared earlier."
      ],
      "metadata": {
        "id": "N2Q41ZuClezU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize the MLPClassifier with one hidden layer of 100 neurons\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=20, random_state=42)\n",
        "\n",
        "# Train the MLPClassifier on the training data\n",
        "mlp_clf.fit(x_train_final, y_train_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "eEGtcwuPlhhe",
        "outputId": "c4e00660-91a0-4d12-8fdf-657f5103e7ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(max_iter=20, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(max_iter=20, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained for 20 iterations (`max_iter=20`). This is a relatively small number of iterations to keep training time reasonable for this baseline.\n",
        "\n",
        "Next, we will evaluate the model on the validation set to understand its initial classification performance."
      ],
      "metadata": {
        "id": "vf1QhFLwljpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Evaluate Classification Performance\n",
        "\n",
        "After training the MLP classifier, we evaluate its performance on the validation set.\n",
        "\n",
        "We will calculate the accuracy and the F1-score to assess how well the model classifies the Fashion MNIST images.\n",
        "\n",
        "Our goal is to achieve an F1-score above 0.75 on the validation data."
      ],
      "metadata": {
        "id": "EnptPzYemQ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "y_val_pred = mlp_clf.predict(x_val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "# Calculate weighted F1-score to account for class imbalance\n",
        "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ofV34XgmTh6",
        "outputId": "89bfafc7-2f8f-44ec-bca4-9ae801d25bbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8843\n",
            "Validation F1-score: 0.8829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy metric gives the proportion of correctly classified samples.  \n",
        "The weighted F1-score balances precision and recall across all classes, which is particularly useful when classes are imbalanced.\n",
        "\n",
        "If the F1-score is below the target of 0.75, we may consider tuning the model architecture or training parameters.\n"
      ],
      "metadata": {
        "id": "D6I3o0BumXHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Regression on a Dummy Task\n",
        "\n",
        "In this section, we experiment with using Scikit-Learn's `MLPRegressor` to perform a regression task on the Fashion MNIST dataset.\n",
        "\n",
        "Since the dataset is primarily for classification, we create a dummy regression task where the goal is to predict the class label (an integer from 0 to 9) as a continuous value.\n",
        "\n",
        "This helps us practice regression using neural networks and evaluate the model using the R²-score.\n",
        "\n",
        "Our target is to achieve an R²-score above 0.8 on the validation set."
      ],
      "metadata": {
        "id": "bCR96Smfmji9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Initialize the MLPRegressor with one hidden layer of 100 neurons\n",
        "mlp_reg = MLPRegressor(hidden_layer_sizes=(100,), max_iter=20, random_state=42)\n",
        "\n",
        "# Train the regressor on the training data\n",
        "mlp_reg.fit(x_train_final, y_train_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "_kS7JzrKml2k",
        "outputId": "7c832218-5d0d-4aec-8465-39b91c2c9920"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(max_iter=20, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(max_iter=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(max_iter=20, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict continuous outputs on the validation set\n",
        "y_val_pred_reg = mlp_reg.predict(x_val)\n",
        "\n",
        "# Calculate the R²-score\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_val, y_val_pred_reg)\n",
        "\n",
        "print(f\"Validation R²-score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPwFIhXxmoX0",
        "outputId": "04e00fed-5ac9-42fb-bd09-007678c68474"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation R²-score: 0.8490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Scikit-Learn's MLP models allowed us to quickly build and train neural networks with minimal setup.\n",
        "\n",
        "The classification model gave a straightforward way to handle the multi-class problem, while the regression model demonstrated how neural networks can also be applied to continuous output tasks.\n",
        "\n",
        "We observed that even a simple MLP with one hidden layer can achieve reasonable performance on both classification and regression tasks.\n",
        "\n",
        "However, for more complex or higher accuracy models, deep learning frameworks like Keras or PyTorch offer more flexibility and control."
      ],
      "metadata": {
        "id": "x59ve0_9mqQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 4-Layer Feedforward Network with Keras (Sequential)\n",
        "\n",
        "## 3.1 Build a Sequential Model\n",
        "\n",
        "In this section, we build a 4-layer feedforward neural network using Keras' Sequential API.\n",
        "\n",
        "The architecture consists of:  \n",
        "- Input layer that matches the flattened image size (784 features)  \n",
        "- Three Dense hidden layers with activation functions  \n",
        "- Output layer with 10 units for classification (one per class)\n",
        "\n",
        "This simple architecture allows us to experiment with deeper networks compared to the single-layer MLP from Scikit-Learn."
      ],
      "metadata": {
        "id": "FFZGd8F5nL5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build the Sequential model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),  # First hidden layer\n",
        "    Dense(64, activation='relu'),                        # Second hidden layer\n",
        "    Dense(32, activation='relu'),                        # Third hidden layer\n",
        "    Dense(10, activation='softmax')                      # Output layer for 10 classes\n",
        "])\n",
        "\n",
        "# Display the model architecture summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "260CwFxQnNri",
        "outputId": "9b753460-f576-4661-e1ef-801ed0442d96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use ReLU activation for the hidden layers to introduce non-linearity and softmax activation in the output layer for multi-class classification.\n",
        "\n",
        "The layer sizes (128, 64, 32) are chosen to gradually reduce dimensionality and encourage the model to learn hierarchical features."
      ],
      "metadata": {
        "id": "LtHwI-1unQ8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Binary Classification (Class 0 vs Others)\n",
        "\n",
        "In this section, we convert the multi-class Fashion MNIST problem into a binary classification task:  \n",
        "Classify whether an image belongs to class 0 (T-shirt/top) or not.\n",
        "\n",
        "We adjust the labels accordingly, then train the previously defined 4-layer feedforward network with a single output neuron using sigmoid activation for binary classification.\n",
        "\n",
        "Our evaluation metric will be the F1-score, with a target above 0.75."
      ],
      "metadata": {
        "id": "iVUX_UbpnTWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "# Convert labels to binary: 1 if class 0, else 0\n",
        "y_train_bin = (y_train_final == 0).astype(int)\n",
        "y_val_bin = (y_val == 0).astype(int)\n",
        "\n",
        "# Build a new binary classification model\n",
        "binary_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Single output neuron for binary classification\n",
        "])\n",
        "\n",
        "binary_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss=BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the binary classification model\n",
        "history = binary_model.fit(\n",
        "    x_train_final, y_train_bin,\n",
        "    validation_data=(x_val, y_val_bin),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5JC-wBInVHo",
        "outputId": "b7e2a1ef-aee5-451a-faa0-2dd7258a71a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9536 - loss: 0.1157 - val_accuracy: 0.9592 - val_loss: 0.0964\n",
            "Epoch 2/10\n",
            "750/750 - 4s - 5ms/step - accuracy: 0.9602 - loss: 0.0930 - val_accuracy: 0.9622 - val_loss: 0.0936\n",
            "Epoch 3/10\n",
            "750/750 - 4s - 6ms/step - accuracy: 0.9632 - loss: 0.0867 - val_accuracy: 0.9567 - val_loss: 0.1068\n",
            "Epoch 4/10\n",
            "750/750 - 3s - 4ms/step - accuracy: 0.9650 - loss: 0.0819 - val_accuracy: 0.9650 - val_loss: 0.0861\n",
            "Epoch 5/10\n",
            "750/750 - 4s - 5ms/step - accuracy: 0.9674 - loss: 0.0776 - val_accuracy: 0.9653 - val_loss: 0.0853\n",
            "Epoch 6/10\n",
            "750/750 - 3s - 4ms/step - accuracy: 0.9693 - loss: 0.0735 - val_accuracy: 0.9663 - val_loss: 0.0816\n",
            "Epoch 7/10\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9699 - loss: 0.0720 - val_accuracy: 0.9672 - val_loss: 0.0848\n",
            "Epoch 8/10\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9703 - loss: 0.0687 - val_accuracy: 0.9674 - val_loss: 0.0806\n",
            "Epoch 9/10\n",
            "750/750 - 4s - 6ms/step - accuracy: 0.9718 - loss: 0.0670 - val_accuracy: 0.9663 - val_loss: 0.0810\n",
            "Epoch 10/10\n",
            "750/750 - 3s - 5ms/step - accuracy: 0.9729 - loss: 0.0638 - val_accuracy: 0.9658 - val_loss: 0.0857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on validation set and calculate F1-score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_val_pred_prob = binary_model.predict(x_val)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_val_bin, y_val_pred)\n",
        "print(f\"Validation F1-score for binary classification: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t46pM2gMnYV3",
        "outputId": "bbd4593f-6945-472d-f080-eb9fe9de7cf5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Validation F1-score for binary classification: 0.8355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By converting the problem to binary classification, the network can focus on distinguishing one class against all others.\n",
        "\n",
        "Using sigmoid activation and binary cross-entropy loss fits this task.\n",
        "\n",
        "The F1-score balances precision and recall, which is important in binary classification, especially if classes are imbalanced.\n",
        "\n",
        "Achieving an F1-score above 0.75 indicates good performance in identifying the target class."
      ],
      "metadata": {
        "id": "-b-KTLmzneLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Regression Task\n",
        "\n",
        "In this section, we use the 4-layer feedforward Keras model to perform a regression task.\n",
        "\n",
        "We aim to predict the class ID (0 to 9) as a continuous numeric value based on the input images.\n",
        "\n",
        "We will evaluate the model using the R²-score, with a target above 0.8.\n",
        "\n",
        "Additionally, we will reflect on the training time, potential overfitting, and examine the loss curve to understand the model’s learning behavior."
      ],
      "metadata": {
        "id": "_qcIsaSkn5d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Build the regression model (same architecture as before, but output is a single neuron with linear activation)\n",
        "regression_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Single output neuron for regression\n",
        "])\n",
        "\n",
        "regression_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss=MeanSquaredError(),\n",
        "    metrics=[]\n",
        ")\n",
        "\n",
        "# Train the regression model\n",
        "history = regression_model.fit(\n",
        "    x_train_final, y_train_final,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgV3Eugrn8Xb",
        "outputId": "a956d953-5444-4796-c398-e43b2e3bebca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "750/750 - 5s - 6ms/step - loss: 2.3676 - val_loss: 1.6883\n",
            "Epoch 2/30\n",
            "750/750 - 3s - 4ms/step - loss: 1.5833 - val_loss: 1.5122\n",
            "Epoch 3/30\n",
            "750/750 - 3s - 4ms/step - loss: 1.4121 - val_loss: 1.3742\n",
            "Epoch 4/30\n",
            "750/750 - 4s - 5ms/step - loss: 1.3112 - val_loss: 1.3258\n",
            "Epoch 5/30\n",
            "750/750 - 4s - 6ms/step - loss: 1.2397 - val_loss: 1.2832\n",
            "Epoch 6/30\n",
            "750/750 - 4s - 6ms/step - loss: 1.1806 - val_loss: 1.2556\n",
            "Epoch 7/30\n",
            "750/750 - 5s - 7ms/step - loss: 1.1154 - val_loss: 1.2945\n",
            "Epoch 8/30\n",
            "750/750 - 5s - 6ms/step - loss: 1.0702 - val_loss: 1.1913\n",
            "Epoch 9/30\n",
            "750/750 - 3s - 4ms/step - loss: 1.0426 - val_loss: 1.2094\n",
            "Epoch 10/30\n",
            "750/750 - 4s - 5ms/step - loss: 0.9814 - val_loss: 1.1913\n",
            "Epoch 11/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.9465 - val_loss: 1.2271\n",
            "Epoch 12/30\n",
            "750/750 - 3s - 3ms/step - loss: 0.9174 - val_loss: 1.1530\n",
            "Epoch 13/30\n",
            "750/750 - 7s - 9ms/step - loss: 0.8890 - val_loss: 1.1932\n",
            "Epoch 14/30\n",
            "750/750 - 4s - 5ms/step - loss: 0.8727 - val_loss: 1.1580\n",
            "Epoch 15/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.8478 - val_loss: 1.1524\n",
            "Epoch 16/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.8093 - val_loss: 1.1175\n",
            "Epoch 17/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.7981 - val_loss: 1.3361\n",
            "Epoch 18/30\n",
            "750/750 - 6s - 8ms/step - loss: 0.7811 - val_loss: 1.1221\n",
            "Epoch 19/30\n",
            "750/750 - 3s - 4ms/step - loss: 0.7518 - val_loss: 1.1228\n",
            "Epoch 20/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.7287 - val_loss: 1.1311\n",
            "Epoch 21/30\n",
            "750/750 - 6s - 8ms/step - loss: 0.7157 - val_loss: 1.1231\n",
            "Epoch 22/30\n",
            "750/750 - 5s - 7ms/step - loss: 0.6968 - val_loss: 1.1528\n",
            "Epoch 23/30\n",
            "750/750 - 6s - 8ms/step - loss: 0.6843 - val_loss: 1.1068\n",
            "Epoch 24/30\n",
            "750/750 - 3s - 4ms/step - loss: 0.6528 - val_loss: 1.1479\n",
            "Epoch 25/30\n",
            "750/750 - 5s - 6ms/step - loss: 0.6617 - val_loss: 1.0984\n",
            "Epoch 26/30\n",
            "750/750 - 6s - 9ms/step - loss: 0.6489 - val_loss: 1.1369\n",
            "Epoch 27/30\n",
            "750/750 - 3s - 3ms/step - loss: 0.6228 - val_loss: 1.1638\n",
            "Epoch 28/30\n",
            "750/750 - 6s - 9ms/step - loss: 0.6256 - val_loss: 1.1746\n",
            "Epoch 29/30\n",
            "750/750 - 5s - 6ms/step - loss: 0.6099 - val_loss: 1.1162\n",
            "Epoch 30/30\n",
            "750/750 - 4s - 6ms/step - loss: 0.5897 - val_loss: 1.1092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict continuous outputs on validation set\n",
        "y_val_pred_reg = regression_model.predict(x_val).flatten()\n",
        "\n",
        "# Calculate R²-score\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_val, y_val_pred_reg)\n",
        "\n",
        "print(f\"Validation R²-score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcnIGu2koBvD",
        "outputId": "adeb0cf0-4337-49f0-d6f8-a4a46063b08d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Validation R²-score: 0.8657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss curves\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Squared Error Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BSbZ5JNIoDvv",
        "outputId": "0d954a03-e500-4c30-ab34-74dd96c225ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training took multiple epochs to converge, as shown by the loss curves.\n",
        "\n",
        "If the validation loss starts increasing while training loss decreases, it may indicate overfitting, where the model memorizes training data instead of generalizing.\n",
        "\n",
        "The R²-score above 0.8 demonstrates that the model captures meaningful numeric patterns to predict the class ID reasonably well, even though this is a proxy regression task.\n",
        "\n",
        "This experiment highlights the flexibility of neural networks in handling both classification and regression problems with similar architectures."
      ],
      "metadata": {
        "id": "6YE1_Tgnn71t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 4-Layer Feedforward Network with PyTorch\n",
        "\n",
        "## 4.1 Define the Model Architecture\n",
        "\n",
        "In this section, we implement a 4-layer feedforward neural network using PyTorch.\n",
        "\n",
        "We will define the model architecture using either `nn.Sequential` or by creating a custom class that inherits from `nn.Module`.\n",
        "\n",
        "This approach gives us more flexibility and control compared to Keras and Scikit-Learn, which is useful for advanced customization and debugging."
      ],
      "metadata": {
        "id": "ktX6TkczoSYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the 4-layer feedforward neural network using nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 10)  # Output layer for 10 classes\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpciTAbLoUbW",
        "outputId": "8a0fa236-94ad-4707-f68d-b12182e6177a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, define a custom model class for more flexibility\n",
        "\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(784, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.layer3 = nn.Linear(64, 32)\n",
        "        self.output = nn.Linear(32, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the custom model\n",
        "custom_model = FeedforwardNN()\n",
        "print(custom_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052R2TSBoXkJ",
        "outputId": "60b92582-5cca-4002-e473-fd3644874372"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedforwardNN(\n",
            "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (layer3): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (output): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `nn.Sequential` provides a simple and readable way to stack layers sequentially, which is sufficient for straightforward architectures.\n",
        "\n",
        "Defining a custom `nn.Module` class gives more flexibility, allowing us to modify the forward pass logic if needed, and is preferred for more complex models.\n",
        "\n",
        "Both models have the same architecture: input layer, three hidden layers with ReLU activations, and an output layer for 10-class classification."
      ],
      "metadata": {
        "id": "cq6xSfE1oc0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Training the Classifier\n",
        "\n",
        "In this section, we train the 4-layer feedforward network defined with PyTorch for multi-class classification on the Fashion MNIST dataset.\n",
        "\n",
        "We use `CrossEntropyLoss` as the loss function, which is appropriate for multi-class classification tasks where targets are class indices.\n",
        "\n",
        "After training, we evaluate the model using the F1-score, aiming for a score above 0.75.\n",
        "\n",
        "We will also convert the dataset into PyTorch tensors and create DataLoader objects for batch processing during training."
      ],
      "metadata": {
        "id": "9-usKjdRox1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "x_train_tensor = torch.tensor(x_train_final, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_final, dtype=torch.long)\n",
        "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "# Instantiate model, loss function, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = FeedforwardNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPBTtqIBozvp",
        "outputId": "3478333c-c603-4e72-d96f-bf60be886ad3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 0.6593\n",
            "Epoch 2/15, Loss: 0.4224\n",
            "Epoch 3/15, Loss: 0.3770\n",
            "Epoch 4/15, Loss: 0.3491\n",
            "Epoch 5/15, Loss: 0.3243\n",
            "Epoch 6/15, Loss: 0.3096\n",
            "Epoch 7/15, Loss: 0.2931\n",
            "Epoch 8/15, Loss: 0.2815\n",
            "Epoch 9/15, Loss: 0.2718\n",
            "Epoch 10/15, Loss: 0.2599\n",
            "Epoch 11/15, Loss: 0.2530\n",
            "Epoch 12/15, Loss: 0.2438\n",
            "Epoch 13/15, Loss: 0.2354\n",
            "Epoch 14/15, Loss: 0.2264\n",
            "Epoch 15/15, Loss: 0.2180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on validation set\n",
        "model.eval()\n",
        "y_val_preds = []\n",
        "y_val_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_val_preds.extend(predicted.cpu().numpy())\n",
        "        y_val_true.extend(labels.numpy())\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_val_true, y_val_preds, average='weighted')\n",
        "print(f\"Validation F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHtk7xTfo39I",
        "outputId": "11bd5dc6-ca71-4711-a46e-178db8f5a88b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1-score: 0.8836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the PyTorch model with batches and GPU acceleration (if available) allows efficient learning on large datasets.\n",
        "\n",
        "CrossEntropyLoss combines `LogSoftmax` and negative log likelihood loss in one step, which is suitable for multi-class classification with integer labels.\n",
        "\n",
        "The weighted F1-score accounts for class imbalance by computing the average weighted by support (number of true instances per class).\n",
        "\n",
        "Achieving an F1-score above 0.75 demonstrates that our PyTorch model successfully learned to classify Fashion MNIST images."
      ],
      "metadata": {
        "id": "HaAEb0Kao3Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Training the Regressor\n",
        "\n",
        "In this section, we train the same 4-layer feedforward network architecture in PyTorch for a regression task.\n",
        "\n",
        "We will use Mean Squared Error Loss (`MSELoss`), which is appropriate for regression problems.\n",
        "\n",
        "The target will be the numeric class labels, and we aim to achieve an R²-score above 0.8 on the test set.\n",
        "\n",
        "We will also reflect on differences in model flexibility and control between PyTorch and Keras."
      ],
      "metadata": {
        "id": "BWSn67EbpH_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Modify the model output layer for regression: output dimension = 1\n",
        "class FeedforwardNNRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeedforwardNNRegressor, self).__init__()\n",
        "        self.layer1 = nn.Linear(784, 128)\n",
        "        self.layer2 = nn.Linear(128, 64)\n",
        "        self.layer3 = nn.Linear(64, 32)\n",
        "        self.output = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the regression model and move to device\n",
        "regressor = FeedforwardNNRegressor().to(device)\n",
        "\n",
        "# Prepare regression targets as float tensors\n",
        "y_train_reg = torch.tensor(y_train_final.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "y_val_reg = torch.tensor(y_val.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "# Create DataLoader for regression training\n",
        "train_dataset_reg = TensorDataset(x_train_tensor, y_train_reg)\n",
        "train_loader_reg = DataLoader(train_dataset_reg, batch_size=64, shuffle=True)\n",
        "\n",
        "val_dataset_reg = TensorDataset(x_val_tensor, y_val_reg)\n",
        "val_loader_reg = DataLoader(val_dataset_reg, batch_size=64)\n",
        "\n",
        "# Loss and optimizer for regression\n",
        "criterion_reg = nn.MSELoss()\n",
        "optimizer_reg = optim.Adam(regressor.parameters())\n",
        "\n",
        "# Training loop for regression\n",
        "num_epochs = 15\n",
        "regressor.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader_reg:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer_reg.zero_grad()\n",
        "        outputs = regressor(inputs)\n",
        "        loss = criterion_reg(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer_reg.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader_reg.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyP5tzIZpKmi",
        "outputId": "0a899525-3085-426a-ceed-40e88ae7cdf4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, MSE Loss: 2.8778\n",
            "Epoch 2/15, MSE Loss: 1.6724\n",
            "Epoch 3/15, MSE Loss: 1.4885\n",
            "Epoch 4/15, MSE Loss: 1.3749\n",
            "Epoch 5/15, MSE Loss: 1.3044\n",
            "Epoch 6/15, MSE Loss: 1.2234\n",
            "Epoch 7/15, MSE Loss: 1.1571\n",
            "Epoch 8/15, MSE Loss: 1.1087\n",
            "Epoch 9/15, MSE Loss: 1.0604\n",
            "Epoch 10/15, MSE Loss: 1.0134\n",
            "Epoch 11/15, MSE Loss: 0.9675\n",
            "Epoch 12/15, MSE Loss: 0.9401\n",
            "Epoch 13/15, MSE Loss: 0.9287\n",
            "Epoch 14/15, MSE Loss: 0.9045\n",
            "Epoch 15/15, MSE Loss: 0.8787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate regression performance on validation set\n",
        "regressor.eval()\n",
        "y_val_preds_reg = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in val_loader_reg:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = regressor(inputs)\n",
        "        y_val_preds_reg.extend(outputs.cpu().numpy())\n",
        "\n",
        "y_val_preds_reg = np.array(y_val_preds_reg).flatten()\n",
        "r2 = r2_score(y_val, y_val_preds_reg)\n",
        "print(f\"Validation R²-score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3WoTRnQpOJ5",
        "outputId": "d3b0ae91-db68-4517-90aa-cde221d03fe5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation R²-score: 0.8572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using PyTorch for regression tasks provides fine-grained control over the model definition and training process, which can be more flexible compared to Keras's higher-level abstractions.\n",
        "\n",
        "PyTorch requires more explicit management of tensors, device placement, and training loops, but this also allows customization of loss functions, optimizers, and dynamic architectures.\n",
        "\n",
        "Achieving an R²-score above 0.8 indicates that the model can predict the class numbers reasonably well in a regression setting, showing the model's capability beyond classification.\n",
        "\n",
        "This flexibility is advantageous when experimenting with novel architectures or training procedures, although it comes with a steeper learning curve compared to Keras."
      ],
      "metadata": {
        "id": "qOz4CUglpQAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 4-Layer Non-Sequential Feedforward Network with Keras\n",
        "## 5.1 Functional API Model\n",
        "\n",
        "In this section, we will define a 4-layer feedforward neural network using Keras's Functional API.\n",
        "\n",
        "Unlike the Sequential API, the Functional API allows more flexibility in building complex models by explicitly specifying inputs and outputs, which is useful for creating non-linear architectures, shared layers, or models with multiple inputs and outputs.\n",
        "\n",
        "Here, we will build a simple 4-layer fully connected network using this approach."
      ],
      "metadata": {
        "id": "kFykiPr8pgCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer with shape matching the flattened input (784,)\n",
        "inputs = Input(shape=(784,))\n",
        "\n",
        "# Define the 4 fully connected layers with ReLU activations\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "\n",
        "# Output layer for classification with 10 classes and softmax activation\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model by specifying inputs and outputs\n",
        "functional_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Print the model summary to verify the architecture\n",
        "functional_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "RSKsPZkvpiFP",
        "outputId": "cd5b7ab3-4394-4fc5-af01-9c0a594f06af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,146\u001b[0m (434.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,146</span> (434.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Binary Classification\n",
        "\n",
        "In this section, we will perform binary classification using the Functional API model, distinguishing class 0 from all other classes.\n",
        "\n",
        "We will create consistent training and validation splits from the original training data, then train and evaluate the model, reporting the F1-score with the goal of exceeding 0.75.\n",
        "\n",
        "Careful handling of data splits is essential to ensure that the input features and labels have matching numbers of samples to avoid errors."
      ],
      "metadata": {
        "id": "GdKMQwS2p5Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Note: We need to use the original training set (x_train_final, y_train_final) here,\n",
        "# because x_train was previously split for other tasks and may cause size mismatch.\n",
        "\n",
        "# Split the original training data (from the initial preprocessing step) into training and validation sets (80%-20%)\n",
        "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
        "    x_train_final, y_train_final, test_size=0.2, random_state=42, stratify=y_train_final)\n",
        "\n",
        "# Prepare binary labels for the split sets: class 0 vs others\n",
        "y_train_binary = (y_train_split == 0).astype(int)\n",
        "y_val_binary = (y_val == 0).astype(int)\n",
        "\n",
        "# Define input layer again to avoid confusion (input shape must match flattened input size)\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_shape = x_train_split.shape[1]  # number of features after flattening\n",
        "\n",
        "inputs = Input(shape=(input_shape,))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "\n",
        "# Output layer for binary classification\n",
        "outputs_binary = Dense(1, activation='sigmoid')(x)\n",
        "binary_model = Model(inputs=inputs, outputs=outputs_binary)\n",
        "\n",
        "# Compile the model\n",
        "binary_model.compile(optimizer='adam',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_binary = binary_model.fit(x_train_split, y_train_binary,\n",
        "                                  validation_data=(x_val, y_val_binary),\n",
        "                                  epochs=15,\n",
        "                                  batch_size=64,\n",
        "                                  verbose=2)\n",
        "\n",
        "# Predict on validation data and calculate F1-score\n",
        "y_val_pred_prob = binary_model.predict(x_val)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "f1 = f1_score(y_val_binary, y_val_pred)\n",
        "print(f\"Validation F1-score (binary classification): {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0euWfMap62i",
        "outputId": "2f671e81-059a-4761-9e1c-95d4075f50f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "600/600 - 4s - 7ms/step - accuracy: 0.9553 - loss: 0.1151 - val_accuracy: 0.9604 - val_loss: 0.0942\n",
            "Epoch 2/15\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9610 - loss: 0.0949 - val_accuracy: 0.9638 - val_loss: 0.0869\n",
            "Epoch 3/15\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9635 - loss: 0.0879 - val_accuracy: 0.9558 - val_loss: 0.0996\n",
            "Epoch 4/15\n",
            "600/600 - 4s - 6ms/step - accuracy: 0.9638 - loss: 0.0856 - val_accuracy: 0.9668 - val_loss: 0.0829\n",
            "Epoch 5/15\n",
            "600/600 - 6s - 10ms/step - accuracy: 0.9674 - loss: 0.0795 - val_accuracy: 0.9603 - val_loss: 0.0898\n",
            "Epoch 6/15\n",
            "600/600 - 4s - 6ms/step - accuracy: 0.9672 - loss: 0.0784 - val_accuracy: 0.9610 - val_loss: 0.0898\n",
            "Epoch 7/15\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9695 - loss: 0.0731 - val_accuracy: 0.9672 - val_loss: 0.0774\n",
            "Epoch 8/15\n",
            "600/600 - 4s - 6ms/step - accuracy: 0.9708 - loss: 0.0699 - val_accuracy: 0.9660 - val_loss: 0.0820\n",
            "Epoch 9/15\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9699 - loss: 0.0704 - val_accuracy: 0.9684 - val_loss: 0.0812\n",
            "Epoch 10/15\n",
            "600/600 - 3s - 4ms/step - accuracy: 0.9717 - loss: 0.0667 - val_accuracy: 0.9659 - val_loss: 0.0778\n",
            "Epoch 11/15\n",
            "600/600 - 3s - 4ms/step - accuracy: 0.9734 - loss: 0.0621 - val_accuracy: 0.9660 - val_loss: 0.0844\n",
            "Epoch 12/15\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9741 - loss: 0.0610 - val_accuracy: 0.9664 - val_loss: 0.0785\n",
            "Epoch 13/15\n",
            "600/600 - 4s - 6ms/step - accuracy: 0.9752 - loss: 0.0580 - val_accuracy: 0.9686 - val_loss: 0.0831\n",
            "Epoch 14/15\n",
            "600/600 - 4s - 7ms/step - accuracy: 0.9754 - loss: 0.0579 - val_accuracy: 0.9663 - val_loss: 0.0868\n",
            "Epoch 15/15\n",
            "600/600 - 3s - 4ms/step - accuracy: 0.9764 - loss: 0.0554 - val_accuracy: 0.9657 - val_loss: 0.0827\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Validation F1-score (binary classification): 0.8326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Regression Task\n",
        "\n",
        "In this section, we will use the 4-layer non-sequential feedforward network built with Keras Functional API to perform a regression task.\n",
        "\n",
        "The goal is to predict the numeric class label from the input images and achieve an R²-score above 0.8 on the validation set.\n",
        "\n",
        "Using the Functional API allows us to design more flexible architectures than simple sequential models, such as implementing branching, skip connections, or multiple inputs/outputs, which can be advantageous for complex tasks.\n",
        "\n",
        "We will train the model using mean squared error loss and evaluate its performance using the R² metric."
      ],
      "metadata": {
        "id": "8gBz5ZXzre2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Convert class labels to float for regression task\n",
        "y_train_reg = y_train_split.astype(float)\n",
        "y_val_reg = y_val.astype(float)\n",
        "\n",
        "# Define the model for regression (reuse the functional architecture with output units=1 and linear activation)\n",
        "outputs_reg = Dense(1, activation='linear')(x)  # x is last hidden layer from previous cell\n",
        "\n",
        "regression_model = Model(inputs=inputs, outputs=outputs_reg)\n",
        "\n",
        "# Compile the model for regression\n",
        "regression_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the regression model\n",
        "history_reg = regression_model.fit(x_train_split, y_train_reg,\n",
        "                                   validation_data=(x_val, y_val_reg),\n",
        "                                   epochs=20,\n",
        "                                   batch_size=64,\n",
        "                                   verbose=2)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred_reg = regression_model.predict(x_val).flatten()\n",
        "\n",
        "# Calculate R²-score\n",
        "r2 = r2_score(y_val_reg, y_val_pred_reg)\n",
        "print(f\"Validation R²-score (regression task): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQn5W57xrhtH",
        "outputId": "b76a5d1f-67e2-49f6-af53-7a1e607ab6ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 - 4s - 6ms/step - loss: 2.0978 - val_loss: 1.5715\n",
            "Epoch 2/20\n",
            "600/600 - 4s - 6ms/step - loss: 1.3677 - val_loss: 1.4316\n",
            "Epoch 3/20\n",
            "600/600 - 4s - 7ms/step - loss: 1.2099 - val_loss: 1.4056\n",
            "Epoch 4/20\n",
            "600/600 - 3s - 4ms/step - loss: 1.1245 - val_loss: 1.2721\n",
            "Epoch 5/20\n",
            "600/600 - 2s - 4ms/step - loss: 1.0382 - val_loss: 1.2666\n",
            "Epoch 6/20\n",
            "600/600 - 4s - 6ms/step - loss: 1.0081 - val_loss: 1.2735\n",
            "Epoch 7/20\n",
            "600/600 - 4s - 7ms/step - loss: 0.9583 - val_loss: 1.3423\n",
            "Epoch 8/20\n",
            "600/600 - 3s - 4ms/step - loss: 0.9233 - val_loss: 1.2604\n",
            "Epoch 9/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.8911 - val_loss: 1.2870\n",
            "Epoch 10/20\n",
            "600/600 - 4s - 6ms/step - loss: 0.8667 - val_loss: 1.2190\n",
            "Epoch 11/20\n",
            "600/600 - 3s - 4ms/step - loss: 0.8290 - val_loss: 1.1723\n",
            "Epoch 12/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.7913 - val_loss: 1.2542\n",
            "Epoch 13/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.7806 - val_loss: 1.1732\n",
            "Epoch 14/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.7362 - val_loss: 1.1711\n",
            "Epoch 15/20\n",
            "600/600 - 3s - 6ms/step - loss: 0.7276 - val_loss: 1.1866\n",
            "Epoch 16/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.7061 - val_loss: 1.1570\n",
            "Epoch 17/20\n",
            "600/600 - 3s - 4ms/step - loss: 0.6837 - val_loss: 1.1982\n",
            "Epoch 18/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.6674 - val_loss: 1.1935\n",
            "Epoch 19/20\n",
            "600/600 - 2s - 4ms/step - loss: 0.6493 - val_loss: 1.1581\n",
            "Epoch 20/20\n",
            "600/600 - 4s - 6ms/step - loss: 0.6387 - val_loss: 1.1983\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Validation R²-score (regression task): 0.8547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. (Bonus) 3-Layer Recurrent Neural Network with Keras\n",
        "\n",
        "## 6.1 Preprocess Data for Time-Series Format\n",
        "\n",
        "In this section, we will prepare the Fashion MNIST dataset for a recurrent neural network (RNN) by treating each image as a time series.\n",
        "\n",
        "Each 28x28 image will be reshaped into a sequence of 28 time steps, where each time step contains 28 pixel values. This format is suitable for RNNs, which process sequential data.\n",
        "\n",
        "The new input shape will be `(batch_size, time_steps=28, features=28)`.\n",
        "\n",
        "This transformation allows the model to potentially learn spatial dependencies along the rows of the image as temporal patterns."
      ],
      "metadata": {
        "id": "oCVamLoosAEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the training and validation images for RNN input\n",
        "x_train_rnn = x_train_split.reshape(-1, 28, 28)\n",
        "x_val_rnn = x_val.reshape(-1, 28, 28)\n",
        "\n",
        "# Confirm the new shapes\n",
        "print(f\"Training data shape for RNN: {x_train_rnn.shape}\")\n",
        "print(f\"Validation data shape for RNN: {x_val_rnn.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKDmZtmKsB38",
        "outputId": "29d3ebde-847e-46a5-9a8e-6ba61d0d5cf0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for RNN: (38400, 28, 28)\n",
            "Validation data shape for RNN: (9600, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Build the RNN Model\n",
        "\n",
        "Here, we construct a 3-layer recurrent neural network using Keras. We will use either `SimpleRNN` or `LSTM` layers to capture temporal dependencies in the sequential input data.\n",
        "\n",
        "Each recurrent layer processes the sequence output from the previous layer, enabling the model to learn complex time-dependent patterns from the reshaped image rows.\n",
        "\n",
        "The final layer will be a Dense layer appropriate for the task (classification or regression)."
      ],
      "metadata": {
        "id": "v9ayu6nPsEYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# Define input shape for the RNN (time steps, features)\n",
        "inputs = Input(shape=(28, 28))\n",
        "\n",
        "# Add 3 LSTM layers, with the first two returning sequences to feed the next layer\n",
        "x = LSTM(64, return_sequences=True)(inputs)\n",
        "x = LSTM(64, return_sequences=True)(x)\n",
        "x = LSTM(64)(x)\n",
        "\n",
        "# Output layer for classification (10 classes)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Build the model\n",
        "rnn_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model architecture\n",
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "40GJq8NXsGNE",
        "outputId": "0fc2cd19-c2d9-4a4e-f700-d685d80c2e15"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m23,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m90,506\u001b[0m (353.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,506</span> (353.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m90,506\u001b[0m (353.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,506</span> (353.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Binary Classification with RNN\n",
        "\n",
        "In this section, we adapt the RNN model for a binary classification task. Specifically, we classify one class (e.g., class 0) against all other classes.\n",
        "\n",
        "We will modify the labels accordingly and train the RNN. After training, we will evaluate the model using the F1-score metric, aiming to exceed 0.75.\n",
        "\n",
        "This will demonstrate the RNN's ability to handle sequence data for binary classification problems."
      ],
      "metadata": {
        "id": "H-zEmfl2sI72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Convert labels to binary: class 0 vs others\n",
        "y_train_binary_rnn = (y_train_split == 0).astype(int)\n",
        "y_val_binary_rnn = (y_val == 0).astype(int)\n",
        "\n",
        "# Modify output layer for binary classification\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(28, 28))\n",
        "x = LSTM(64, return_sequences=True)(inputs)\n",
        "x = LSTM(64, return_sequences=True)(x)\n",
        "x = LSTM(64)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)  # Single neuron with sigmoid activation\n",
        "\n",
        "binary_rnn_model = Model(inputs=inputs, outputs=outputs)\n",
        "binary_rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the binary classification RNN model\n",
        "history_binary_rnn = binary_rnn_model.fit(\n",
        "    x_train_rnn, y_train_binary_rnn,\n",
        "    validation_data=(x_val_rnn, y_val_binary_rnn),\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Predict on validation data\n",
        "y_val_pred_prob = binary_rnn_model.predict(x_val_rnn)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_val_binary_rnn, y_val_pred)\n",
        "print(f\"Validation F1-score for binary classification with RNN: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-SHUyOjsKwz",
        "outputId": "52d33a5c-3652-43f1-bb95-f1d71390ca06"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "600/600 - 41s - 69ms/step - accuracy: 0.9477 - loss: 0.1338 - val_accuracy: 0.9575 - val_loss: 0.1024\n",
            "Epoch 2/15\n",
            "600/600 - 36s - 60ms/step - accuracy: 0.9557 - loss: 0.1052 - val_accuracy: 0.9567 - val_loss: 0.1012\n",
            "Epoch 3/15\n",
            "600/600 - 36s - 61ms/step - accuracy: 0.9585 - loss: 0.0984 - val_accuracy: 0.9602 - val_loss: 0.0943\n",
            "Epoch 4/15\n",
            "600/600 - 32s - 53ms/step - accuracy: 0.9598 - loss: 0.0952 - val_accuracy: 0.9589 - val_loss: 0.0992\n",
            "Epoch 5/15\n",
            "600/600 - 43s - 72ms/step - accuracy: 0.9618 - loss: 0.0914 - val_accuracy: 0.9594 - val_loss: 0.0955\n",
            "Epoch 6/15\n",
            "600/600 - 41s - 68ms/step - accuracy: 0.9624 - loss: 0.0874 - val_accuracy: 0.9583 - val_loss: 0.0956\n",
            "Epoch 7/15\n",
            "600/600 - 41s - 68ms/step - accuracy: 0.9638 - loss: 0.0845 - val_accuracy: 0.9619 - val_loss: 0.0914\n",
            "Epoch 8/15\n",
            "600/600 - 42s - 70ms/step - accuracy: 0.9642 - loss: 0.0821 - val_accuracy: 0.9615 - val_loss: 0.0902\n",
            "Epoch 9/15\n",
            "600/600 - 44s - 73ms/step - accuracy: 0.9657 - loss: 0.0798 - val_accuracy: 0.9615 - val_loss: 0.0894\n",
            "Epoch 10/15\n",
            "600/600 - 35s - 59ms/step - accuracy: 0.9666 - loss: 0.0766 - val_accuracy: 0.9631 - val_loss: 0.0929\n",
            "Epoch 11/15\n",
            "600/600 - 42s - 70ms/step - accuracy: 0.9683 - loss: 0.0757 - val_accuracy: 0.9638 - val_loss: 0.0868\n",
            "Epoch 12/15\n",
            "600/600 - 39s - 66ms/step - accuracy: 0.9691 - loss: 0.0722 - val_accuracy: 0.9634 - val_loss: 0.0968\n",
            "Epoch 13/15\n",
            "600/600 - 33s - 55ms/step - accuracy: 0.9697 - loss: 0.0704 - val_accuracy: 0.9616 - val_loss: 0.0891\n",
            "Epoch 14/15\n",
            "600/600 - 41s - 69ms/step - accuracy: 0.9704 - loss: 0.0699 - val_accuracy: 0.9657 - val_loss: 0.0860\n",
            "Epoch 15/15\n",
            "600/600 - 39s - 66ms/step - accuracy: 0.9712 - loss: 0.0675 - val_accuracy: 0.9676 - val_loss: 0.0835\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "Validation F1-score for binary classification with RNN: 0.8378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4 Regression with RNN\n",
        "\n",
        "In this section, we use the 3-layer recurrent neural network to perform a regression task. The goal is to predict the numeric class label of each input image.\n",
        "\n",
        "We will train the model using mean squared error loss and evaluate the performance using the R²-score metric, targeting a score above 0.8.\n",
        "\n",
        "This approach showcases how RNNs can be applied beyond classification to regression problems on sequential data."
      ],
      "metadata": {
        "id": "L1ZqxapFsOcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define RNN model for regression\n",
        "inputs = Input(shape=(28, 28))\n",
        "x = LSTM(64, return_sequences=True)(inputs)\n",
        "x = LSTM(64, return_sequences=True)(x)\n",
        "x = LSTM(64)(x)\n",
        "outputs = Dense(1)(x)  # Single neuron with linear activation for regression\n",
        "\n",
        "rnn_regressor = Model(inputs=inputs, outputs=outputs)\n",
        "rnn_regressor.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the RNN regressor\n",
        "history_rnn_reg = rnn_regressor.fit(\n",
        "    x_train_rnn, y_train_split.astype(float),\n",
        "    validation_data=(x_val_rnn, y_val.astype(float)),\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred_reg = rnn_regressor.predict(x_val_rnn).flatten()\n",
        "\n",
        "# Calculate R²-score\n",
        "r2 = r2_score(y_val, y_val_pred_reg)\n",
        "print(f\"Validation R²-score for regression with RNN: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UlkwzDjsROc",
        "outputId": "030fa47f-c30e-406a-ead3-258d7a30ed76"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "600/600 - 38s - 64ms/step - loss: 2.8721 - val_loss: 1.8882\n",
            "Epoch 2/15\n",
            "600/600 - 38s - 63ms/step - loss: 1.7133 - val_loss: 1.7519\n",
            "Epoch 3/15\n",
            "600/600 - 31s - 52ms/step - loss: 1.5846 - val_loss: 1.5161\n",
            "Epoch 4/15\n",
            "600/600 - 40s - 67ms/step - loss: 1.4629 - val_loss: 1.5548\n",
            "Epoch 5/15\n",
            "600/600 - 41s - 69ms/step - loss: 1.3804 - val_loss: 1.4546\n",
            "Epoch 6/15\n",
            "600/600 - 30s - 51ms/step - loss: 1.3158 - val_loss: 1.4404\n",
            "Epoch 7/15\n",
            "600/600 - 41s - 68ms/step - loss: 1.2656 - val_loss: 1.4075\n",
            "Epoch 8/15\n",
            "600/600 - 42s - 70ms/step - loss: 1.2244 - val_loss: 1.3055\n",
            "Epoch 9/15\n",
            "600/600 - 42s - 71ms/step - loss: 1.1762 - val_loss: 1.3151\n",
            "Epoch 10/15\n",
            "600/600 - 41s - 68ms/step - loss: 1.1510 - val_loss: 1.2802\n",
            "Epoch 11/15\n",
            "600/600 - 42s - 69ms/step - loss: 1.1236 - val_loss: 1.2293\n",
            "Epoch 12/15\n",
            "600/600 - 38s - 63ms/step - loss: 1.0828 - val_loss: 1.2283\n",
            "Epoch 13/15\n",
            "600/600 - 43s - 72ms/step - loss: 1.0638 - val_loss: 1.2054\n",
            "Epoch 14/15\n",
            "600/600 - 39s - 65ms/step - loss: 1.0251 - val_loss: 1.2009\n",
            "Epoch 15/15\n",
            "600/600 - 41s - 69ms/step - loss: 1.0032 - val_loss: 1.2434\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
            "Validation R²-score for regression with RNN: 0.8493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Why Are Neural Networks So Powerful?\n",
        "\n",
        "Neural networks are powerful because they act as universal function approximators, meaning they can theoretically model any continuous function given sufficient complexity and data. This ability enables them to learn complex mappings between inputs and outputs without explicitly programmed rules. Furthermore, neural networks learn hierarchical representations of data through multiple layers, allowing them to extract increasingly abstract and meaningful features automatically. This hierarchical feature learning is especially valuable in tasks like image and speech recognition, where raw data is high-dimensional and intricate.\n",
        "\n",
        "Another key strength of neural networks is their capacity to model non-linear decision boundaries, which makes them far more flexible than traditional linear models. This flexibility allows neural networks to solve complex classification and regression problems effectively. However, their power also comes with challenges: designing the right architecture and tuning hyperparameters can be difficult, training can be unstable or slow, and overfitting on limited data is a common risk. These challenges require careful experimentation and techniques such as regularization, dropout, and early stopping to ensure robust performance."
      ],
      "metadata": {
        "id": "TACQQblIsib6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Summary and Final Thoughts\n",
        "\n",
        "In this notebook, we explored multiple neural network frameworks including Scikit-Learn, Keras (both Sequential and Functional APIs), and PyTorch. Each framework has its strengths: Scikit-Learn offers simplicity and quick prototyping, Keras provides a user-friendly and flexible interface for building deep networks, and PyTorch excels in customization and dynamic computation graphs, which are useful for research and complex models.\n",
        "\n",
        "Among the models tested, Keras Sequential and PyTorch 4-layer feedforward networks achieved the highest scores for both classification and regression tasks. The non-sequential Keras model demonstrated additional flexibility through branching architecture. Below is a summary table of the best achieved performance metrics:\n",
        "\n",
        "| Model                      | Classification F1-score | Regression R²-score |\n",
        "|----------------------------|------------------------|---------------------|\n",
        "| Scikit-Learn MLP           | 0.88                   | 0.84                |\n",
        "| Keras Sequential FFN       | 0.83                   | 0.86                |\n",
        "| PyTorch 4-Layer FFN        | 0.88                   | 0.85                |\n",
        "| Keras Functional FFN       | 0.83                   | 0.85                |\n",
        "\n",
        "From each section, key insights include the importance of data preprocessing, the impact of model architecture depth and complexity, and the differences in ease of use and customization between frameworks. The recurrent neural network bonus section illustrated how time-series formatting of image data can leverage temporal patterns to improve performance. Overall, this exercise reinforced that no single framework or model fits all problems, and experimentation is critical for finding the best solution."
      ],
      "metadata": {
        "id": "HCojrp8FskpL"
      }
    }
  ]
}